{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf 2.0부터 keras는 tensorflow의 공식 API\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_row', 40000)\n",
    "pd.set_option('display.max_column', 10000)\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "# Log Data가 저장될 디렉터리 경로 만들기\n",
    "dir_name = \"Learning_log\"\n",
    "\n",
    "def make_Tensorboard_dir(dir_name):\n",
    "    root_logdir = os.path.join(os.curdir, dir_name)\n",
    "    sub_dir_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    return os.path.join(root_logdir, sub_dir_name)\n",
    "\n",
    "from os.path import join\n",
    "import sqlite3\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list: ['sac/2879724.db', 'sac/2861103.db', 'sac/2877843.db', 'sac/2877820.db', 'sac/2879773.db', 'sac/2881064.db', 'sac/2879783.db', 'sac/2880217.db', 'sac/2861195.db', 'sac/2860939.db']\n",
      "(19899, 3, 10)\n",
      "(19898, 1)\n"
     ]
    }
   ],
   "source": [
    "path = \"sac/*\" #-------------------------자신의 db파일이 있는 폴더로 수정---------------------------\n",
    "file_list =  glob.glob(path)\n",
    "file_list_db = [file for file in file_list if file.endswith(\".db\")]\n",
    "print (\"file_list: {}\".format(file_list_db))\n",
    "len(file_list_db)\n",
    "# EventCode03이 일어났을 당시의 초당 주행기록 가져오기\n",
    "\n",
    "time_slice = 3\n",
    "\n",
    "temp1 = np.zeros((1,time_slice,10)) # srcrec_df2 초기화\n",
    "\n",
    "srcrec_df2 =temp1 # 연결한 db들의 x data 저장소\n",
    "srcrec_df4 = pd.DataFrame() # 연결한 db들의 y data 저장소\n",
    "\n",
    "for i in range (0,len(file_list_db)):\n",
    "    # event 파일 가져오기\n",
    "    f = open('src/event.csv') #-------------------------자신의 event파일이 있는 폴더로 수정---------------------------\n",
    "    csvReader = csv.reader(f)\n",
    "    # db연결\n",
    "    conn = sqlite3.connect(file_list_db[i])\n",
    "    c = conn. cursor()\n",
    "    # event 테이블 유무 확인 후, 있으면 제거\n",
    "    c.execute('Drop Table If Exists event')\n",
    "    # event 테이블 생성\n",
    "    c.execute(\"create table event(CAR_RECDRV_KEY integer, EVENT_CODE text, EVENT_STDT text, EVENT_ENDT text)\")\n",
    "    # csv 파일 읽어 온 데이터 insert\n",
    "    for row in csvReader:\n",
    "        if row[7] == \"EVENT_CODE\":\n",
    "            continue\n",
    "        sql1 = \"insert into event (CAR_RECDRV_KEY,EVENT_CODE, EVENT_STDT, EVENT_ENDT) values (?,?,?,?)\"\n",
    "        key= int(row[1])\n",
    "        #key 추출\n",
    "        if key != int(file_list_db[i][4:11]): #src에 자신의 db파일이 있어야함, 아니면 인덱스 수정할 것\n",
    "            continue\n",
    "        code = (row[7])\n",
    "        #event 추출\n",
    "        if code[-11:] != \"EventCode03\" and code[-11:] != \"EventCode02\" and code[-11:] != \"EventCode10\":\n",
    "            continue\n",
    "        stdt = (row[8])\n",
    "        endt = (row[9])\n",
    "        c.execute(sql1,(key,code,stdt,endt))\n",
    "    #트랜잭션 저장\n",
    "    conn.commit()\n",
    "    #event03 뽐기 query 실행\n",
    "    sql2 = 'SELECT SRCREC.srcValue, SRCREC.realTime, SRCREC.srcSpeed, SRCREC.srcAPS,\\\n",
    "    SRCREC.srcGyroValue, SRCREC.srcRPM, SRCREC.srcTPS, SRCREC.srcMAF, SRCREC.srcEngineLoad, ifnull(EVENT_CODE, \"0\") FROM SRCREC LEFT OUTER JOIN\\\n",
    "    (SELECT EVENT_CODE, EVENT_STDT s, EVENT_ENDT e FROM event\\\n",
    "    ) ON SRCREC.realTime BETWEEN strftime(\"%Y%m%d%H%M%S\",s)\\\n",
    "     AND strftime(\"%Y%m%d%H%M%S\",e)'\n",
    "    query =  c.execute(sql2)\n",
    "    cols = [column[0] for column in query.description]\n",
    "    srcrec_df = pd.DataFrame.from_records(data=query.fetchall(), columns=cols)\n",
    "    \n",
    "    # 슬라이딩 윈도우 적용\n",
    "    srcrec_df = srcrec_df.iloc[100:]\n",
    "    srcred_list =  srcrec_df.values\n",
    "    seq_len = time_slice\n",
    "    data_matrix=[]\n",
    "    for i in range(0, len(srcred_list)-seq_len+1): # data를 겹친다. 0 1 2 3 4 5 -> 1 2 3 4 5 6\n",
    "        tmp_data = srcrec_df[i:i+seq_len]\n",
    "        data_matrix.append(tmp_data)\n",
    "    data_matrix_np = np.array(data_matrix)\n",
    "   \n",
    "    if len(data_matrix_np)==0:\n",
    "        continue\n",
    "    # 각 db의 슬라이딩 적용한 x data들 합치기\n",
    "    srcrec_df2 = np.concatenate([srcrec_df2,data_matrix_np])\n",
    "    \n",
    "    # y data 뽑아오기\n",
    "    sql3 = 'SELECT ifnull(EVENT_CODE, \"0\") FROM SRCREC LEFT OUTER JOIN\\\n",
    "    (SELECT EVENT_CODE, EVENT_STDT s, EVENT_ENDT e FROM event\\\n",
    "    ) ON SRCREC.realTime BETWEEN strftime(\"%Y%m%d%H%M%S\",s)\\\n",
    "     AND strftime(\"%Y%m%d%H%M%S\",e)'\n",
    "    query =  c.execute(sql3)\n",
    "    cols = [column[0] for column in query.description]\n",
    "    srcrec_df3 = pd.DataFrame.from_records(data=query.fetchall(), columns=cols)\n",
    "    \n",
    "    # 슬라이딩 적용으로 인해 필요없는 y data 제거\n",
    "    srcrec_df3 = srcrec_df3.iloc[100 + time_slice - 1:] \n",
    "    \n",
    "    # 각 db의 슬라이딩 적용한 y data들 합치기\n",
    "    srcrec_df4 = pd.concat([srcrec_df4, srcrec_df3], ignore_index=True)\n",
    "    \n",
    "    #db 연결 종료\n",
    "    c.close()\n",
    "    conn.close()\n",
    "    #파일 연결 종료\n",
    "    f.close()\n",
    "# srcrec_df2 : x data\n",
    "# srcrec_df4 : y data\n",
    "print(srcrec_df2.shape)\n",
    "print(srcrec_df4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. srcrec_df2를 초기화할 때 넣어준 0을 지움\n",
    "2. 여러 컬럼 중 x data에 사용할 컬럼들을 걸러냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = srcrec_df2[1:,:,2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = srcrec_df4.values[:,0] # EVENT_CODE\n",
    "y_data = pd.get_dummies(y_data).values\n",
    "y_data_temp = y_data.copy()\n",
    "\n",
    "# normal \n",
    "temp = y_data[:,0] \n",
    "\n",
    "where_1 = np.where(temp == 1)\n",
    "\n",
    "temp[where_1] = 0\n",
    "\n",
    "# EventCode02\n",
    "temp2 = y_data[:,1]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 1\n",
    "\n",
    "# EventCode03\n",
    "temp2 = y_data[:,2]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 2\n",
    "\n",
    "# EventCode10\n",
    "temp2 = y_data[:,3]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 3\n",
    "\n",
    "# HardEventCode02\n",
    "temp2 = y_data[:,4]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 1\n",
    "\n",
    "# HardEventCode03\n",
    "temp2 = y_data[:,5]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 2\n",
    "\n",
    "# HardEventCode10\n",
    "temp2 = y_data[:,6]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 3\n",
    "\n",
    "# RawEventCode02\n",
    "temp2 = y_data[:,7]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 1\n",
    "\n",
    "# RawEventCode03\n",
    "temp2 = y_data[:,8]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 2\n",
    "\n",
    "# RawEventCode10\n",
    "temp2 = y_data[:,9]\n",
    "\n",
    "where_1 = np.where(temp2 == 1)\n",
    "\n",
    "temp[where_1] = 3\n",
    "\n",
    "# one hot encoding\n",
    "temp = to_categorical(temp) # normal , eventcode02, eventcode03, eventcode10\n",
    "y_data = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change from sequence x data to image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imaging time series as unthresholded recurrence plot\n",
    "def r_plot(data,delay=0):\n",
    "    #input datatype data : ndarray, 1xn, n-number of samples in each series\n",
    "    #input datatype delay : int, delay embedding for RP formation, default value is 1\n",
    "    #output datatype rp : ndarray, nxn, unthresholded recurrence plot for series\n",
    "    transformed = np.zeros([2,len(data)-delay])\n",
    "    transformed[0,:] = data[0:len(data)-delay]\n",
    "    transformed[1,:] = data[delay:len(data)]\n",
    "    rp = np.zeros([len(data)-delay,len(data)-delay])\n",
    "    for i in range(len(rp)):\n",
    "        temp = np.tile(transformed[:,i],(len(rp),1)).T-transformed\n",
    "        temp2 = np.square(temp)\n",
    "        rp[i,:] = np.sum(temp2,axis=0)\n",
    "    return np.array(rp).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#RP embedding\n",
    "total = []\n",
    "for row in range(0, len(x_data)):\n",
    "    RP=[]\n",
    "    for col in range(0, len(x_data[row][0])):       \n",
    "        toy_data=x_data[row,:,col]\n",
    "        RP.append(r_plot(toy_data))\n",
    "    total.append(RP)\n",
    "    \n",
    "total2 = []\n",
    "for rp in total:\n",
    "    RP2 = []\n",
    "    myrp2 ={}\n",
    "    for i in range(0, time_slice):\n",
    "        myrp2[i] = np.zeros((time_slice,6))\n",
    "    for rp_count in range(0, len(myrp2)):\n",
    "        myrp = myrp2[rp_count]\n",
    "        rp_mini_count=0;\n",
    "        for rp_mini in rp:\n",
    "            for index in range(0, len(rp_mini[0])):\n",
    "                myrp[index][rp_mini_count] = rp_mini[rp_count][index]\n",
    "            rp_mini_count = rp_mini_count+1\n",
    "            \n",
    "    for key, value in myrp2.items():\n",
    "        RP2.append(value)\n",
    "        \n",
    "    total2.append(RP2)        \n",
    "\n",
    "print(len(total2[0]))\n",
    "print(len(total2[0][0]))\n",
    "print(len(total2[0][0][0]))\n",
    "x_data = total2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the 0 and 1 ratio the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19898\n",
      "225\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "yindex=0\n",
    "y1index=0# ydata가 1인 개수를 센거\n",
    "x1_data = []\n",
    "y1_data = []\n",
    "\n",
    "print(len(y_data))\n",
    "for ydata in y_data:\n",
    "    if ydata[1] == 1:\n",
    "        x1_data.append(x_data[yindex])\n",
    "        y1_data.append(y_data[yindex])\n",
    "        y1index= y1index+1\n",
    "    yindex = yindex+1\n",
    "print(y1index)\n",
    "\n",
    "yindex=0\n",
    "y2getindex=0 #2인 데이터 카운트\n",
    "for ydata in y_data:\n",
    "    if ydata[2] == 1:\n",
    "        if y2getindex == y1index:\n",
    "            break\n",
    "        x1_data.append(x_data[yindex])\n",
    "        y1_data.append(y_data[yindex])\n",
    "        y2getindex= y2getindex+1\n",
    "    yindex = yindex+1\n",
    "\n",
    "yindex=0\n",
    "y1getindex=0 #가져오는 데이터 카운트 \n",
    "for ydata in y_data:\n",
    "    if ydata[0] == 1:\n",
    "        if y1getindex == math.floor(y1index*1.5):# event: normal = 1 : 1.5\n",
    "            break\n",
    "        x1_data.append(x_data[yindex])\n",
    "        y1_data.append(y_data[yindex])\n",
    "        y1getindex= y1getindex+1\n",
    "    yindex = yindex+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.80000000e+01 0.00000000e+00 2.70265608e-03 3.16808000e+05 0.00000000e+00 0.00000000e+00]\n",
      "   [7.20000000e+01 5.19800441e+01 2.20291339e-02 3.16808000e+05 1.11034206e+02 0.00000000e+00]]\n",
      "\n",
      "  [[1.80000000e+01 0.00000000e+00 2.70265608e-03 3.16808000e+05 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.80000000e+01 5.19800441e+01 4.01638569e-02 0.00000000e+00 1.11034206e+02 0.00000000e+00]]\n",
      "\n",
      "  [[7.20000000e+01 5.19800441e+01 2.20291339e-02 3.16808000e+05 1.11034206e+02 0.00000000e+00]\n",
      "   [1.80000000e+01 5.19800441e+01 4.01638569e-02 0.00000000e+00 1.11034206e+02 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.80000000e+01 5.19800441e+01 4.01638569e-02 0.00000000e+00 1.11034206e+02 0.00000000e+00]\n",
      "   [2.88000000e+02 5.19800441e+01 8.64423872e-02 2.53800450e+06 1.11034206e+02 2.12592200e+02]]\n",
      "\n",
      "  [[1.80000000e+01 5.19800441e+01 4.01638569e-02 0.00000000e+00 1.11034206e+02 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.62000000e+02 0.00000000e+00 2.44451221e-01 2.53800450e+06 0.00000000e+00 2.12592200e+02]]\n",
      "\n",
      "  [[2.88000000e+02 5.19800441e+01 8.64423872e-02 2.53800450e+06 1.11034206e+02 2.12592200e+02]\n",
      "   [1.62000000e+02 0.00000000e+00 2.44451221e-01 2.53800450e+06 0.00000000e+00 2.12592200e+02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.62000000e+02 0.00000000e+00 2.44451221e-01 2.53800450e+06 0.00000000e+00 2.12592200e+02]\n",
      "   [3.38000000e+02 1.50711261e+01 7.08001569e+00 2.53800450e+06 6.02845042e+01 9.05676800e+02]]\n",
      "\n",
      "  [[1.62000000e+02 0.00000000e+00 2.44451221e-01 2.53800450e+06 0.00000000e+00 2.12592200e+02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [3.20000000e+01 1.50711261e+01 4.69333142e+00 0.00000000e+00 6.02845042e+01 2.40681800e+02]]\n",
      "\n",
      "  [[3.38000000e+02 1.50711261e+01 7.08001569e+00 2.53800450e+06 6.02845042e+01 9.05676800e+02]\n",
      "   [3.20000000e+01 1.50711261e+01 4.69333142e+00 0.00000000e+00 6.02845042e+01 2.40681800e+02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [7.20000000e+01 6.79431021e+02 2.55281784e-03 0.00000000e+00 6.02845042e+01 1.72236800e+02]\n",
      "   [2.88000000e+02 6.79431021e+02 7.82819875e-01 2.09305800e+06 6.02845042e+01 1.72236800e+02]]\n",
      "\n",
      "  [[7.20000000e+01 6.79431021e+02 2.55281784e-03 0.00000000e+00 6.02845042e+01 1.72236800e+02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [7.20000000e+01 0.00000000e+00 6.95965835e-01 2.09305800e+06 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[2.88000000e+02 6.79431021e+02 7.82819875e-01 2.09305800e+06 6.02845042e+01 1.72236800e+02]\n",
      "   [7.20000000e+01 0.00000000e+00 6.95965835e-01 2.09305800e+06 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [7.20000000e+01 0.00000000e+00 6.95965835e-01 2.09305800e+06 0.00000000e+00 0.00000000e+00]\n",
      "   [3.92000000e+02 1.10726533e+01 2.56328824e+00 2.09305800e+06 2.76816567e+02 2.56737800e+02]]\n",
      "\n",
      "  [[7.20000000e+01 0.00000000e+00 6.95965835e-01 2.09305800e+06 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.28000000e+02 1.10726533e+01 5.87953986e-01 0.00000000e+00 2.76816567e+02 2.56737800e+02]]\n",
      "\n",
      "  [[3.92000000e+02 1.10726533e+01 2.56328824e+00 2.09305800e+06 2.76816567e+02 2.56737800e+02]\n",
      "   [1.28000000e+02 1.10726533e+01 5.87953986e-01 0.00000000e+00 2.76816567e+02 2.56737800e+02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.28000000e+02 1.10726533e+01 5.87953986e-01 0.00000000e+00 2.76816567e+02 2.56737800e+02]\n",
      "   [2.88000000e+02 1.10726533e+01 2.98250772e+00 1.54012500e+05 2.76816567e+02 2.56737800e+02]]\n",
      "\n",
      "  [[1.28000000e+02 1.10726533e+01 5.87953986e-01 0.00000000e+00 2.76816567e+02 2.56737800e+02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [3.20000000e+01 0.00000000e+00 9.22007588e-01 1.54012500e+05 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[2.88000000e+02 1.10726533e+01 2.98250772e+00 1.54012500e+05 2.76816567e+02 2.56737800e+02]\n",
      "   [3.20000000e+01 0.00000000e+00 9.22007588e-01 1.54012500e+05 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [2.00000000e+00 1.23031572e+00 4.89595671e-02 7.56450000e+03 0.00000000e+00 5.37920000e+00]\n",
      "   [1.80000000e+01 1.23031572e+00 2.44795921e+00 7.56450000e+03 0.00000000e+00 5.37920000e+00]]\n",
      "\n",
      "  [[2.00000000e+00 1.23031572e+00 4.89595671e-02 7.56450000e+03 0.00000000e+00 5.37920000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [8.00000000e+00 0.00000000e+00 1.80452864e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[1.80000000e+01 1.23031572e+00 2.44795921e+00 7.56450000e+03 0.00000000e+00 5.37920000e+00]\n",
      "   [8.00000000e+00 0.00000000e+00 1.80452864e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [8.00000000e+00 0.00000000e+00 1.80452864e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [7.20000000e+01 0.00000000e+00 2.73403137e+00 1.86245000e+04 0.00000000e+00 3.51122000e+01]]\n",
      "\n",
      "  [[8.00000000e+00 0.00000000e+00 1.80452864e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [3.20000000e+01 0.00000000e+00 9.62012169e-02 1.86245000e+04 0.00000000e+00 3.51122000e+01]]\n",
      "\n",
      "  [[7.20000000e+01 0.00000000e+00 2.73403137e+00 1.86245000e+04 0.00000000e+00 3.51122000e+01]\n",
      "   [3.20000000e+01 0.00000000e+00 9.62012169e-02 1.86245000e+04 0.00000000e+00 3.51122000e+01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [3.20000000e+01 0.00000000e+00 9.62012169e-02 1.86245000e+04 0.00000000e+00 3.51122000e+01]\n",
      "   [3.20000000e+01 1.25982282e+03 7.91354980e-01 1.86245000e+04 9.41945324e+03 1.88129780e+03]]\n",
      "\n",
      "  [[3.20000000e+01 0.00000000e+00 9.62012169e-02 1.86245000e+04 0.00000000e+00 3.51122000e+01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 1.25982282e+03 3.35725382e-01 0.00000000e+00 9.41945324e+03 2.43043920e+03]]\n",
      "\n",
      "  [[3.20000000e+01 1.25982282e+03 7.91354980e-01 1.86245000e+04 9.41945324e+03 1.88129780e+03]\n",
      "   [0.00000000e+00 1.25982282e+03 3.35725382e-01 0.00000000e+00 9.41945324e+03 2.43043920e+03]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.80000000e+01 2.76817273e+00 3.74219164e+00 1.00352000e+05 1.10726721e+03 1.28018000e+01]\n",
      "   [9.80000000e+01 1.50711261e+01 7.54570893e+00 1.00352000e+05 1.50711261e+03 1.28018000e+01]]\n",
      "\n",
      "  [[1.80000000e+01 2.76817273e+00 3.74219164e+00 1.00352000e+05 1.10726721e+03 1.28018000e+01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [3.20000000e+01 4.92117506e+00 6.60108911e-01 0.00000000e+00 3.07572657e+01 0.00000000e+00]]\n",
      "\n",
      "  [[9.80000000e+01 1.50711261e+01 7.54570893e+00 1.00352000e+05 1.50711261e+03 1.28018000e+01]\n",
      "   [3.20000000e+01 4.92117506e+00 6.60108911e-01 0.00000000e+00 3.07572657e+01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]]\n",
      "(774, 3, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(x1_data)\n",
    "y_data = np.array(y1_data)\n",
    "print(x_data[:10])\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00005\n",
    "training_epochs = 700\n",
    "batch_size = 128\n",
    "\n",
    "tf.random.set_seed(777) # weight 초기화용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n",
      "541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trnx, tstx, trny, tsty = train_test_split(x_data, y_data, test_size=0.3, random_state=111)\n",
    "# trnx = np.expand_dims(trnx,axis=-1)\n",
    "# tstx = np.expand_dims(tstx,axis=-1)\n",
    "print(len(trnx))\n",
    "print(len(trny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()#이제 계층을 순차적으로 연결 가능\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME', \n",
    "                              input_shape=(time_slice, time_slice, 6)))# input_shape => 첫 layer에만 선언\n",
    "model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "#수정사항 2, softmax\n",
    "model.add(keras.layers.Dense(4, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          1760      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 128,164\n",
      "Trainable params: 128,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#수정사항 categorical\n",
    "model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = learning_rate,) , metrics=['accuracy'])\n",
    "\n",
    "# 텐서보드에 기록\n",
    "TB_log_dir = make_Tensorboard_dir(dir_name)\n",
    "TensorB = tf.keras.callbacks.TensorBoard(log_dir = TB_log_dir)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 541 samples, validate on 233 samples\n",
      "Epoch 1/700\n",
      "128/541 [======>.......................] - ETA: 12s - loss: 1059.5259 - accuracy: 0.2969WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.243187). Check your callbacks.\n",
      "541/541 [==============================] - 4s 8ms/sample - loss: 688.2329 - accuracy: 0.3142 - val_loss: 494.1113 - val_accuracy: 0.2790\n",
      "Epoch 2/700\n",
      "541/541 [==============================] - 0s 101us/sample - loss: 435.9735 - accuracy: 0.2957 - val_loss: 440.1922 - val_accuracy: 0.2833\n",
      "Epoch 3/700\n",
      "541/541 [==============================] - 0s 264us/sample - loss: 309.7709 - accuracy: 0.3309 - val_loss: 381.6576 - val_accuracy: 0.2833\n",
      "Epoch 4/700\n",
      "541/541 [==============================] - 0s 111us/sample - loss: 219.7573 - accuracy: 0.3235 - val_loss: 234.9074 - val_accuracy: 0.2961\n",
      "Epoch 5/700\n",
      "541/541 [==============================] - 0s 104us/sample - loss: 133.0438 - accuracy: 0.3346 - val_loss: 146.1235 - val_accuracy: 0.4249\n",
      "Epoch 6/700\n",
      "541/541 [==============================] - 0s 120us/sample - loss: 114.2917 - accuracy: 0.4362 - val_loss: 132.5004 - val_accuracy: 0.3133\n",
      "Epoch 7/700\n",
      "541/541 [==============================] - 0s 111us/sample - loss: 75.6732 - accuracy: 0.3919 - val_loss: 90.5549 - val_accuracy: 0.3391\n",
      "Epoch 8/700\n",
      "541/541 [==============================] - 0s 98us/sample - loss: 55.4867 - accuracy: 0.3937 - val_loss: 80.7220 - val_accuracy: 0.3519\n",
      "Epoch 9/700\n",
      "541/541 [==============================] - 0s 95us/sample - loss: 45.4701 - accuracy: 0.4104 - val_loss: 60.9818 - val_accuracy: 0.3476\n",
      "Epoch 10/700\n",
      "541/541 [==============================] - 0s 95us/sample - loss: 30.7860 - accuracy: 0.4436 - val_loss: 88.1645 - val_accuracy: 0.4292\n",
      "Epoch 11/700\n",
      "541/541 [==============================] - 0s 92us/sample - loss: 50.9804 - accuracy: 0.4843 - val_loss: 83.8761 - val_accuracy: 0.3562\n",
      "Epoch 12/700\n",
      "541/541 [==============================] - 0s 93us/sample - loss: 56.5201 - accuracy: 0.4325 - val_loss: 80.2148 - val_accuracy: 0.4206\n",
      "Epoch 13/700\n",
      "541/541 [==============================] - 0s 92us/sample - loss: 54.7932 - accuracy: 0.4566 - val_loss: 70.9061 - val_accuracy: 0.3991\n",
      "Epoch 14/700\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 39.5289 - accuracy: 0.4492 - val_loss: 103.9713 - val_accuracy: 0.3648\n",
      "Epoch 15/700\n",
      "541/541 [==============================] - 0s 107us/sample - loss: 77.2953 - accuracy: 0.4732 - val_loss: 135.4326 - val_accuracy: 0.3519\n",
      "Epoch 16/700\n",
      "541/541 [==============================] - 0s 93us/sample - loss: 96.9571 - accuracy: 0.4214 - val_loss: 145.9887 - val_accuracy: 0.3562\n",
      "Epoch 17/700\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 69.8327 - accuracy: 0.4233 - val_loss: 54.7329 - val_accuracy: 0.3605\n",
      "Epoch 18/700\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 34.1286 - accuracy: 0.4787 - val_loss: 90.0067 - val_accuracy: 0.5064\n",
      "Epoch 19/700\n",
      "541/541 [==============================] - 0s 92us/sample - loss: 49.0348 - accuracy: 0.5323 - val_loss: 59.4005 - val_accuracy: 0.4335\n",
      "Epoch 20/700\n",
      "541/541 [==============================] - 0s 102us/sample - loss: 38.7436 - accuracy: 0.5009 - val_loss: 47.6568 - val_accuracy: 0.4206\n",
      "Epoch 21/700\n",
      "541/541 [==============================] - 0s 100us/sample - loss: 32.8402 - accuracy: 0.4732 - val_loss: 47.7036 - val_accuracy: 0.4292\n",
      "Epoch 22/700\n",
      "541/541 [==============================] - 0s 98us/sample - loss: 27.9119 - accuracy: 0.5416 - val_loss: 59.2484 - val_accuracy: 0.3948\n",
      "Epoch 23/700\n",
      "541/541 [==============================] - 0s 174us/sample - loss: 59.3434 - accuracy: 0.4529 - val_loss: 141.2920 - val_accuracy: 0.3433\n",
      "Epoch 24/700\n",
      "541/541 [==============================] - 0s 182us/sample - loss: 104.6916 - accuracy: 0.4011 - val_loss: 165.4015 - val_accuracy: 0.3476\n",
      "Epoch 25/700\n",
      "541/541 [==============================] - 0s 98us/sample - loss: 107.9812 - accuracy: 0.4233 - val_loss: 124.2712 - val_accuracy: 0.3906\n",
      "Epoch 26/700\n",
      "541/541 [==============================] - 0s 98us/sample - loss: 95.7643 - accuracy: 0.4695 - val_loss: 130.5885 - val_accuracy: 0.4378\n",
      "Epoch 27/700\n",
      "541/541 [==============================] - 0s 95us/sample - loss: 83.9787 - accuracy: 0.5083 - val_loss: 100.2328 - val_accuracy: 0.4163\n",
      "Epoch 28/700\n",
      "541/541 [==============================] - 0s 126us/sample - loss: 70.1935 - accuracy: 0.4603 - val_loss: 98.8763 - val_accuracy: 0.3863\n",
      "Epoch 29/700\n",
      "541/541 [==============================] - 0s 137us/sample - loss: 65.7008 - accuracy: 0.4732 - val_loss: 76.7695 - val_accuracy: 0.4335\n",
      "Epoch 30/700\n",
      "541/541 [==============================] - 0s 124us/sample - loss: 53.6058 - accuracy: 0.5139 - val_loss: 75.9781 - val_accuracy: 0.4249\n",
      "Epoch 31/700\n",
      "541/541 [==============================] - 0s 106us/sample - loss: 49.6034 - accuracy: 0.4713 - val_loss: 74.8542 - val_accuracy: 0.3906\n",
      "Epoch 32/700\n",
      "541/541 [==============================] - 0s 111us/sample - loss: 39.3100 - accuracy: 0.4954 - val_loss: 36.3132 - val_accuracy: 0.4506\n",
      "Epoch 33/700\n",
      "541/541 [==============================] - 0s 125us/sample - loss: 28.8128 - accuracy: 0.5028 - val_loss: 83.9880 - val_accuracy: 0.4077\n",
      "Epoch 34/700\n",
      "541/541 [==============================] - 0s 120us/sample - loss: 47.7176 - accuracy: 0.5083 - val_loss: 49.0071 - val_accuracy: 0.4549\n",
      "Epoch 35/700\n",
      "541/541 [==============================] - 0s 96us/sample - loss: 53.6891 - accuracy: 0.5139 - val_loss: 87.6338 - val_accuracy: 0.4120\n",
      "Epoch 36/700\n",
      "541/541 [==============================] - 0s 131us/sample - loss: 54.3046 - accuracy: 0.5102 - val_loss: 59.3073 - val_accuracy: 0.4421\n",
      "Epoch 37/700\n",
      "541/541 [==============================] - 0s 128us/sample - loss: 27.9820 - accuracy: 0.5878 - val_loss: 77.4845 - val_accuracy: 0.5451\n",
      "Epoch 38/700\n",
      "541/541 [==============================] - 0s 144us/sample - loss: 30.9335 - accuracy: 0.5823 - val_loss: 100.7247 - val_accuracy: 0.4249\n",
      "Epoch 39/700\n",
      "541/541 [==============================] - 0s 96us/sample - loss: 66.1646 - accuracy: 0.5102 - val_loss: 74.9986 - val_accuracy: 0.4249\n",
      "Epoch 40/700\n",
      "541/541 [==============================] - 0s 159us/sample - loss: 41.0726 - accuracy: 0.5009 - val_loss: 47.5863 - val_accuracy: 0.4506\n",
      "Epoch 41/700\n",
      "541/541 [==============================] - 0s 237us/sample - loss: 27.8312 - accuracy: 0.5379 - val_loss: 60.2846 - val_accuracy: 0.5236\n",
      "Epoch 42/700\n",
      "541/541 [==============================] - 0s 137us/sample - loss: 40.2321 - accuracy: 0.5823 - val_loss: 84.0318 - val_accuracy: 0.4335\n",
      "Epoch 43/700\n",
      "541/541 [==============================] - 0s 92us/sample - loss: 34.3255 - accuracy: 0.5582 - val_loss: 62.2907 - val_accuracy: 0.4893\n",
      "Epoch 44/700\n",
      "541/541 [==============================] - 0s 94us/sample - loss: 29.7627 - accuracy: 0.5638 - val_loss: 56.7927 - val_accuracy: 0.5021\n",
      "Epoch 45/700\n",
      "541/541 [==============================] - 0s 122us/sample - loss: 34.3015 - accuracy: 0.5860 - val_loss: 45.2729 - val_accuracy: 0.4807\n",
      "Epoch 46/700\n",
      "541/541 [==============================] - 0s 106us/sample - loss: 31.8685 - accuracy: 0.5749 - val_loss: 39.9439 - val_accuracy: 0.4850\n",
      "Epoch 47/700\n",
      "541/541 [==============================] - 0s 124us/sample - loss: 20.3272 - accuracy: 0.6100 - val_loss: 34.0266 - val_accuracy: 0.5236\n",
      "Epoch 48/700\n",
      "541/541 [==============================] - 0s 99us/sample - loss: 17.8264 - accuracy: 0.5804 - val_loss: 54.5418 - val_accuracy: 0.4549\n",
      "Epoch 49/700\n",
      "541/541 [==============================] - 0s 96us/sample - loss: 44.8289 - accuracy: 0.5582 - val_loss: 73.3629 - val_accuracy: 0.4807\n",
      "Epoch 50/700\n",
      "541/541 [==============================] - 0s 92us/sample - loss: 51.9643 - accuracy: 0.5490 - val_loss: 74.1600 - val_accuracy: 0.4421\n",
      "Epoch 51/700\n",
      "541/541 [==============================] - 0s 115us/sample - loss: 57.4739 - accuracy: 0.4917 - val_loss: 85.1042 - val_accuracy: 0.4292\n",
      "Epoch 52/700\n",
      "541/541 [==============================] - 0s 93us/sample - loss: 52.6377 - accuracy: 0.5213 - val_loss: 61.8078 - val_accuracy: 0.4678\n",
      "Epoch 53/700\n",
      "541/541 [==============================] - 0s 95us/sample - loss: 47.3264 - accuracy: 0.5582 - val_loss: 59.7733 - val_accuracy: 0.4721\n",
      "Epoch 54/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 0s 100us/sample - loss: 31.0951 - accuracy: 0.5693 - val_loss: 36.6512 - val_accuracy: 0.5107\n",
      "Epoch 55/700\n",
      "541/541 [==============================] - 0s 99us/sample - loss: 24.3012 - accuracy: 0.5970 - val_loss: 77.4006 - val_accuracy: 0.4979\n",
      "Epoch 56/700\n",
      "541/541 [==============================] - 0s 103us/sample - loss: 53.6375 - accuracy: 0.5786 - val_loss: 93.7776 - val_accuracy: 0.4506\n",
      "Epoch 57/700\n",
      "541/541 [==============================] - 0s 109us/sample - loss: 43.0819 - accuracy: 0.5582 - val_loss: 35.4181 - val_accuracy: 0.4850\n",
      "Epoch 58/700\n",
      "541/541 [==============================] - 0s 95us/sample - loss: 34.2893 - accuracy: 0.5952 - val_loss: 79.1757 - val_accuracy: 0.4335\n",
      "Epoch 59/700\n",
      "541/541 [==============================] - 0s 95us/sample - loss: 48.1211 - accuracy: 0.5250 - val_loss: 80.8705 - val_accuracy: 0.4464\n",
      "Epoch 60/700\n",
      "541/541 [==============================] - 0s 172us/sample - loss: 44.9699 - accuracy: 0.5323 - val_loss: 64.7328 - val_accuracy: 0.4764\n",
      "Epoch 61/700\n",
      "541/541 [==============================] - 0s 251us/sample - loss: 36.0049 - accuracy: 0.5896 - val_loss: 60.1853 - val_accuracy: 0.4936\n",
      "Epoch 62/700\n",
      "541/541 [==============================] - 0s 113us/sample - loss: 36.8038 - accuracy: 0.5693 - val_loss: 94.2167 - val_accuracy: 0.4807\n",
      "Epoch 63/700\n",
      "541/541 [==============================] - 0s 111us/sample - loss: 52.3440 - accuracy: 0.5915 - val_loss: 65.8908 - val_accuracy: 0.4721\n",
      "Epoch 64/700\n",
      "541/541 [==============================] - 0s 126us/sample - loss: 35.0506 - accuracy: 0.5527 - val_loss: 49.4202 - val_accuracy: 0.4635\n",
      "Epoch 65/700\n",
      "541/541 [==============================] - 0s 128us/sample - loss: 24.8792 - accuracy: 0.5656 - val_loss: 23.8045 - val_accuracy: 0.5665\n",
      "Epoch 66/700\n",
      "541/541 [==============================] - 0s 121us/sample - loss: 20.5317 - accuracy: 0.6248 - val_loss: 23.3310 - val_accuracy: 0.5923\n",
      "Epoch 67/700\n",
      "541/541 [==============================] - 0s 135us/sample - loss: 15.4868 - accuracy: 0.6211 - val_loss: 28.0262 - val_accuracy: 0.5622\n",
      "Epoch 68/700\n",
      "541/541 [==============================] - 0s 142us/sample - loss: 14.4741 - accuracy: 0.6192 - val_loss: 26.3436 - val_accuracy: 0.5451\n",
      "Epoch 69/700\n",
      "541/541 [==============================] - 0s 118us/sample - loss: 13.3350 - accuracy: 0.6174 - val_loss: 33.6472 - val_accuracy: 0.6052\n",
      "Epoch 70/700\n",
      "541/541 [==============================] - 0s 110us/sample - loss: 23.5524 - accuracy: 0.6063 - val_loss: 38.3314 - val_accuracy: 0.5021\n",
      "Epoch 71/700\n",
      "541/541 [==============================] - 0s 134us/sample - loss: 24.4930 - accuracy: 0.6044 - val_loss: 42.2809 - val_accuracy: 0.5064\n",
      "Epoch 72/700\n",
      "541/541 [==============================] - 0s 129us/sample - loss: 23.4967 - accuracy: 0.6322 - val_loss: 56.1710 - val_accuracy: 0.5579\n",
      "Epoch 73/700\n",
      "541/541 [==============================] - 0s 80us/sample - loss: 30.0977 - accuracy: 0.6211 - val_loss: 48.6071 - val_accuracy: 0.5236\n",
      "Epoch 74/700\n",
      "541/541 [==============================] - 0s 115us/sample - loss: 35.5330 - accuracy: 0.5804 - val_loss: 60.2370 - val_accuracy: 0.4893\n",
      "Epoch 75/700\n",
      "541/541 [==============================] - 0s 97us/sample - loss: 35.8127 - accuracy: 0.5767 - val_loss: 58.2765 - val_accuracy: 0.4678\n",
      "Epoch 76/700\n",
      "541/541 [==============================] - 0s 107us/sample - loss: 50.8614 - accuracy: 0.5749 - val_loss: 108.9254 - val_accuracy: 0.4764\n",
      "Epoch 77/700\n",
      "541/541 [==============================] - 0s 118us/sample - loss: 57.9448 - accuracy: 0.5823 - val_loss: 63.0196 - val_accuracy: 0.5236\n",
      "Epoch 78/700\n",
      "541/541 [==============================] - 0s 226us/sample - loss: 43.8213 - accuracy: 0.5933 - val_loss: 86.1937 - val_accuracy: 0.4549\n",
      "Epoch 79/700\n",
      "541/541 [==============================] - 0s 134us/sample - loss: 54.6798 - accuracy: 0.5453 - val_loss: 99.9240 - val_accuracy: 0.4506\n",
      "Epoch 80/700\n",
      "541/541 [==============================] - 0s 107us/sample - loss: 65.3211 - accuracy: 0.5471 - val_loss: 93.2723 - val_accuracy: 0.4506\n",
      "Epoch 81/700\n",
      "541/541 [==============================] - 0s 107us/sample - loss: 48.8747 - accuracy: 0.5804 - val_loss: 56.6485 - val_accuracy: 0.5279\n",
      "Epoch 82/700\n",
      "541/541 [==============================] - 0s 105us/sample - loss: 33.9980 - accuracy: 0.6285 - val_loss: 48.2119 - val_accuracy: 0.5494\n",
      "Epoch 83/700\n",
      "541/541 [==============================] - 0s 94us/sample - loss: 26.4542 - accuracy: 0.6266 - val_loss: 42.1801 - val_accuracy: 0.5536\n",
      "Epoch 84/700\n",
      "541/541 [==============================] - 0s 112us/sample - loss: 22.8959 - accuracy: 0.6248 - val_loss: 25.6263 - val_accuracy: 0.5837\n",
      "Epoch 85/700\n",
      "541/541 [==============================] - 0s 97us/sample - loss: 25.6483 - accuracy: 0.6322 - val_loss: 41.9796 - val_accuracy: 0.5150\n",
      "Epoch 86/700\n",
      "541/541 [==============================] - 0s 104us/sample - loss: 28.0917 - accuracy: 0.5952 - val_loss: 27.9649 - val_accuracy: 0.5794\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=trnx, y=trny, validation_data = (tstx, tsty), batch_size = batch_size, epochs = training_epochs,callbacks=[early_stopping, TensorB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57939917\n",
      "0.6051502\n"
     ]
    }
   ],
   "source": [
    "# test data 마지막 정확도\n",
    "print(history.history['val_accuracy'][-1])\n",
    "# test data 가장 높은 정확도\n",
    "print(np.max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 : 0\n",
      "실제 : 0 ->  55\n",
      "실제 : 1 ->  7\n",
      "실제 : 2 ->  1\n",
      "실제 : 3 ->  0\n",
      "---------------------\n",
      "예측 : 1\n",
      "실제 : 0 ->  24\n",
      "실제 : 1 ->  34\n",
      "실제 : 2 ->  21\n",
      "실제 : 3 ->  0\n",
      "---------------------\n",
      "예측 : 2\n",
      "실제 : 0 ->  28\n",
      "실제 : 1 ->  17\n",
      "실제 : 2 ->  46\n",
      "실제 : 3 ->  0\n",
      "---------------------\n",
      "예측 : 3\n",
      "실제 : 0 ->  0\n",
      "실제 : 1 ->  0\n",
      "실제 : 2 ->  0\n",
      "실제 : 3 ->  0\n",
      "---------------------\n",
      "전체데이터 개수 :  233\n",
      "0.5793991416309013\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델인 mip_function에 test 데이터를 입력하면 model이 예측한 event03 유무가 나옵니다.\n",
    "# 해당 유무를 실제 event03유무와 비교하여 출력합니다.\n",
    "y_pred = model.predict(tstx, batch_size=batch_size)\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "d = 0\n",
    "e = 0\n",
    "f = 0\n",
    "g = 0\n",
    "h = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "n = 0\n",
    "o = 0\n",
    "p = 0\n",
    "s = 0\n",
    "t = 0\n",
    "\n",
    "for i in range(len(y_pred[:,0])) :\n",
    "    if y_pred[i,:].argmax() == 0: # event02, 03 발생 X\n",
    "        if tsty[i,0] == 1 :\n",
    "            a = a + 1\n",
    "        elif tsty[i,1] == 1 :\n",
    "            b = b + 1\n",
    "        elif tsty[i,2] == 1 :\n",
    "            c = c + 1\n",
    "        elif tsty[i,3] == 1 :\n",
    "            d = d + 1\n",
    "    elif y_pred[i,:].argmax() == 1: # event02 발생 \n",
    "        if tsty[i,0] == 1 :\n",
    "            e = e + 1\n",
    "        elif tsty[i,1] == 1 :\n",
    "            f = f + 1\n",
    "        elif tsty[i,2] == 1 :\n",
    "            g = g + 1\n",
    "        elif tsty[i,3] == 1 :\n",
    "            h = h + 1\n",
    "    elif y_pred[i,:].argmax() == 2: # event03 발생\n",
    "        if tsty[i,0] == 1 :\n",
    "            k = k + 1\n",
    "        elif tsty[i,1] == 1 :\n",
    "            l = l + 1\n",
    "        elif tsty[i,2] == 1 :\n",
    "            m = m + 1\n",
    "        elif tsty[i,3] == 1 :\n",
    "            n = n + 1\n",
    "    elif y_pred[i,:].argmax() == 3: # event10 발생\n",
    "        if tsty[i,0] == 1 :\n",
    "            o = o + 1\n",
    "        elif tsty[i,1] == 1 :\n",
    "            p = p + 1\n",
    "        elif tsty[i,2] == 1 :\n",
    "            s = s + 1\n",
    "        elif tsty[i,3] == 1 :\n",
    "            t = t + 1\n",
    "\n",
    "print(\"예측 : 0\")\n",
    "print(\"실제 : 0 -> \", a)\n",
    "print(\"실제 : 1 -> \", b)\n",
    "print(\"실제 : 2 -> \", c)\n",
    "print(\"실제 : 3 -> \", d)\n",
    "print(\"---------------------\")\n",
    "print(\"예측 : 1\")\n",
    "print(\"실제 : 0 -> \", e)\n",
    "print(\"실제 : 1 -> \", f)\n",
    "print(\"실제 : 2 -> \", g)\n",
    "print(\"실제 : 3 -> \", h)\n",
    "print(\"---------------------\")\n",
    "print(\"예측 : 2\")\n",
    "print(\"실제 : 0 -> \", k)\n",
    "print(\"실제 : 1 -> \", l)\n",
    "print(\"실제 : 2 -> \", m)\n",
    "print(\"실제 : 3 -> \", n)\n",
    "print(\"---------------------\")\n",
    "print(\"예측 : 3\")\n",
    "print(\"실제 : 0 -> \", o)\n",
    "print(\"실제 : 1 -> \", p)\n",
    "print(\"실제 : 2 -> \", s)\n",
    "print(\"실제 : 3 -> \", t)\n",
    "print(\"---------------------\")\n",
    "print(\"전체데이터 개수 : \", len(y_pred[:,0]))\n",
    "print((a+f+m+t)/len(y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
